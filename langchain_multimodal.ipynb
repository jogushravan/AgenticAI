{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "812a4dbc-fe04-4b84-bdf9-390045e30806",
      "metadata": {
        "id": "812a4dbc-fe04-4b84-bdf9-390045e30806"
      },
      "source": [
        "# Multi-modal RAG with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecXPgawqG7XH",
      "metadata": {
        "id": "ecXPgawqG7XH"
      },
      "source": [
        "## SetUp\n",
        "\n",
        "Install the dependencies you need to run the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133b74f6",
      "metadata": {
        "id": "133b74f6"
      },
      "outputs": [],
      "source": [
        "# for linux\n",
        "# %sudo apt-get install poppler-utils tesseract-ocr libmagic-dev\n",
        "\n",
        "# for mac\n",
        "# %brew install poppler tesseract libmagic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2nDWBTrhn-_M",
      "metadata": {
        "id": "2nDWBTrhn-_M"
      },
      "outputs": [],
      "source": [
        "%pip install -Uq \"unstructured[all-docs]\" pillow lxml pillow\n",
        "%pip install -Uq chromadb tiktoken\n",
        "%pip install -Uq langchain langchain-community langchain-openai langchain-groq\n",
        "%pip install -Uq python_dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91106e31",
      "metadata": {
        "id": "91106e31",
        "outputId": "fb35d92c-c338-4b78-bacb-5da648093f6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# keys for the services we will use\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "os.environ[\"GROQ_API_KEY\"] = \"sk-...\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"sk-...\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74b56bde-1ba0-4525-a11d-cab02c5659e4",
      "metadata": {
        "id": "74b56bde-1ba0-4525-a11d-cab02c5659e4"
      },
      "source": [
        "## Extract the data\n",
        "\n",
        "Extract the elements of the PDF that we will be able to use in the retrieval process. These elements can be: Text, Images, Tables, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62ec070",
      "metadata": {
        "id": "e62ec070"
      },
      "source": [
        "### Partition PDF tables, text, and images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a046528-8d22-4f4e-a520-962026562939",
      "metadata": {
        "id": "0a046528-8d22-4f4e-a520-962026562939",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "output_path = \"./content/\"\n",
        "file_path = output_path + 'attention.pdf'\n",
        "\n",
        "# Reference: https://docs.unstructured.io/open-source/core-functionality/chunking\n",
        "chunks = partition_pdf(\n",
        "    filename=file_path,\n",
        "    infer_table_structure=True,            # extract tables\n",
        "    strategy=\"hi_res\",                     # mandatory to infer tables\n",
        "\n",
        "    extract_image_block_types=[\"Image\"],   # Add 'Table' to list to extract image of tables\n",
        "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
        "\n",
        "    extract_image_block_to_payload=True,   # if true, will extract base64 for API usage\n",
        "\n",
        "    chunking_strategy=\"by_title\",          # or 'basic'\n",
        "    max_characters=10000,                  # defaults to 500\n",
        "    combine_text_under_n_chars=2000,       # defaults to 0\n",
        "    new_after_n_chars=6000,\n",
        "\n",
        "    # extract_images_in_pdf=True,          # deprecated\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "038f6733",
      "metadata": {
        "id": "038f6733"
      },
      "outputs": [],
      "source": [
        "# We get 2 types of elements from the partition_pdf function\n",
        "set([str(type(el)) for el in chunks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cccca0db",
      "metadata": {
        "id": "cccca0db"
      },
      "outputs": [],
      "source": [
        "# Each CompositeElement containes a bunch of related elements.\n",
        "# This makes it easy to use these elements together in a RAG pipeline.\n",
        "\n",
        "chunks[3].metadata.orig_elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8766f03",
      "metadata": {
        "id": "b8766f03"
      },
      "outputs": [],
      "source": [
        "# This is what an extracted image looks like.\n",
        "# It contains the base64 representation only because we set the param extract_image_block_to_payload=True\n",
        "\n",
        "elements = chunks[3].metadata.orig_elements\n",
        "chunk_images = [el for el in elements if 'Image' in str(type(el))]\n",
        "chunk_images[0].to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26caebda",
      "metadata": {
        "id": "26caebda"
      },
      "source": [
        "### Separate extracted elements into tables, text, and images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8326a750",
      "metadata": {
        "id": "8326a750"
      },
      "outputs": [],
      "source": [
        "# separate tables from texts\n",
        "tables = []\n",
        "texts = []\n",
        "\n",
        "for chunk in chunks:\n",
        "    if \"Table\" in str(type(chunk)):\n",
        "        tables.append(chunk)\n",
        "\n",
        "    if \"CompositeElement\" in str(type((chunk))):\n",
        "        texts.append(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df548e46",
      "metadata": {
        "id": "df548e46"
      },
      "outputs": [],
      "source": [
        "# Get the images from the CompositeElement objects\n",
        "def get_images_base64(chunks):\n",
        "    images_b64 = []\n",
        "    for chunk in chunks:\n",
        "        if \"CompositeElement\" in str(type(chunk)):\n",
        "            chunk_els = chunk.metadata.orig_elements\n",
        "            for el in chunk_els:\n",
        "                if \"Image\" in str(type(el)):\n",
        "                    images_b64.append(el.metadata.image_base64)\n",
        "    return images_b64\n",
        "\n",
        "images = get_images_base64(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9582f462",
      "metadata": {
        "id": "9582f462"
      },
      "source": [
        "#### Check what the images look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83158c36",
      "metadata": {
        "id": "83158c36"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def display_base64_image(base64_code):\n",
        "    # Decode the base64 string to binary\n",
        "    image_data = base64.b64decode(base64_code)\n",
        "    # Display the image\n",
        "    display(Image(data=image_data))\n",
        "\n",
        "display_base64_image(images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf",
      "metadata": {
        "id": "0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf"
      },
      "source": [
        "## Summarize the data\n",
        "\n",
        "Create a summary of each element extracted from the PDF. This summary will be vectorized and used in the retrieval process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b55862c",
      "metadata": {
        "id": "8b55862c"
      },
      "source": [
        "### Text and Table summaries\n",
        "\n",
        "We don't need a multimodal model to generate the summaries of the tables and the text. I will use open source models available on Groq."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b3d2bc",
      "metadata": {
        "id": "08b3d2bc",
        "outputId": "5c39beb3-2a0c-44b8-c2b2-48a4e451282c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uq langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523e6ed2-2132-4748-bdb7-db765f20648d",
      "metadata": {
        "id": "523e6ed2-2132-4748-bdb7-db765f20648d"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c22e3f-42fb-4a4a-a87a-89f10ba8ab99",
      "metadata": {
        "id": "22c22e3f-42fb-4a4a-a87a-89f10ba8ab99"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "prompt_text = \"\"\"\n",
        "You are an assistant tasked with summarizing tables and text.\n",
        "Give a concise summary of the table or text.\n",
        "\n",
        "Respond only with the summary, no additionnal comment.\n",
        "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
        "Just give the summary as it is.\n",
        "\n",
        "Table or text chunk: {element}\n",
        "\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
        "\n",
        "# Summary chain\n",
        "model = ChatGroq(temperature=0.5, model=\"llama-3.1-8b-instant\")\n",
        "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f176b374-aef0-48f4-a104-fb26b1dd6922",
      "metadata": {
        "id": "f176b374-aef0-48f4-a104-fb26b1dd6922"
      },
      "outputs": [],
      "source": [
        "# Summarize text\n",
        "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 3})\n",
        "\n",
        "# Summarize tables\n",
        "tables_html = [table.metadata.text_as_html for table in tables]\n",
        "table_summaries = summarize_chain.batch(tables_html, {\"max_concurrency\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d172ad2",
      "metadata": {
        "id": "1d172ad2",
        "outputId": "1ba65afb-c9cd-4503-c154-db7841dfc1d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The paper \"Attention Is All You Need\" by Ashish Vaswani et al. introduces the Transformer model, a new network architecture based on attention mechanisms, replacing traditional encoder-decoder models. The Transformer achieves state-of-the-art results on two machine translation tasks, improving over existing best results, and generalizes well to other tasks, such as English constituency parsing.',\n",
              " 'Recurrent neural networks have been established as state of the art in sequence modeling and transduction problems, but their sequential nature limits parallelization and requires computational efficiency improvements through factorization tricks and conditional computation. Attention mechanisms have improved sequence modeling, but typically require a recurrent network. The Transformer model proposes to use attention mechanisms entirely, eschewing recurrence and allowing for more parallelization and improved translation quality.',\n",
              " 'The Transformer model has an encoder-decoder structure, where the encoder maps input symbols to continuous representations and the decoder generates output symbols one element at a time. The model architecture consists of stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder and decoder stacks each have 6 identical layers with two or three sub-layers, using residual connections and layer normalization.',\n",
              " 'The attention function maps a query and key-value pairs to an output, computed as a weighted sum of the values, where the weights are the compatibility function of the query with the keys. There are two main types: Scaled Dot-Product Attention and Additive Attention. The Scaled Dot-Product Attention uses a dot product of the query with the keys, scaled by √dk, and applies a softmax function to obtain the weights. This method is faster and more space-efficient than Additive Attention, but Additive Attention outperforms it for larger key dimensions.',\n",
              " 'Multi-head attention is a method that linearly projects queries, keys and values h times with different learned linear projections, then performs attention in parallel, allowing the model to jointly attend to information from different representation subspaces at different positions. The output values are concatenated and projected to yield final values. The Transformer model uses multi-head attention in encoder-decoder attention layers, self-attention layers in the encoder, and self-attention layers in the decoder, with a total of 8 parallel attention layers.',\n",
              " 'The encoder and decoder layers in the model contain a fully connected feed-forward network (FFN) with two linear transformations and a ReLU activation in between. The FFN is applied separately to each position, with different parameters for each layer. The model uses learned embeddings to convert input and output tokens to vectors and applies a linear transformation and softmax function to predict next-token probabilities. The embedding layers share the same weight matrix with the pre-softmax linear transformation.',\n",
              " 'Positional encoding is used to incorporate sequence order into a model, as traditional models lack recurrence or convolution. A sinusoidal function is used to create positional encoding, which is hypothesized to allow the model to learn to attend by relative positions. The model can easily learn to attend by relative positions since the sinusoidal function of the position can be represented as a linear function of the sinusoidal function of the position offset. This allows the model to handle longer sequence lengths.',\n",
              " 'The training regime for our models involved using standard WMT datasets, byte-pair encoding, and batching by approximate sequence length. Models were trained on 8 NVIDIA P100 GPUs with the Adam optimizer and varied learning rates. Training times ranged from 12 hours for base models to 3.5 days for big models.',\n",
              " 'The model uses residual dropout and label smoothing to improve accuracy and BLEU score. The big transformer model achieves a new state-of-the-art BLEU score of 28.4 on English-to-German and 41.0 on English-to-French translation tasks, outperforming previous models at a lower training cost.',\n",
              " \"The Transformer model's importance was evaluated by varying its components and measuring performance changes on English-to-German translation. The base model was modified in different ways, with some components having varying TFLOPS values, and results were measured on a development set.\",\n",
              " 'The study investigates the performance of the Transformer model in different settings. It varies the number of attention heads, attention key and value dimensions, and model size to find the best settings for the model. The results show that single-head attention is worse than the best setting, reducing the attention key size hurts model quality, and bigger models with dropout are better. The model also generalizes well to English constituency parsing, achieving good results in both supervised and semi-supervised settings.',\n",
              " 'The Transformer model, the first sequence transduction model based entirely on attention, outperforms previous models in translation tasks, achieving a new state of the art in English-to-German and English-to-French translation tasks.',\n",
              " \"Research papers on computer vision and neural machine translation are cited, including works by Szegedy et al. on the inception architecture, Vinyals et al. on grammar as a foreign language, Wu et al. on Google's neural machine translation system, and Zhu et al. on shift-reduce constituent parsing. Figures 3, 4, and 5 illustrate the attention mechanism in neural networks, showing attention heads attending to distant dependencies and exhibiting behavior related to sentence structure.\"]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1feadda-8171-4aed-9a60-320a88dc9ee1",
      "metadata": {
        "id": "b1feadda-8171-4aed-9a60-320a88dc9ee1"
      },
      "source": [
        "### Image summaries\n",
        "\n",
        "We will use gpt-4o-mini to produce the image summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c825e1",
      "metadata": {
        "id": "32c825e1",
        "outputId": "3ef8d057-2214-41e8-80e1-c5f902a01ac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uq langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e6b1d97-4245-45ac-95ba-9bc1cfd10182",
      "metadata": {
        "id": "9e6b1d97-4245-45ac-95ba-9bc1cfd10182"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt_template = \"\"\"Describe the image in detail. For context,\n",
        "                  the image is part of a research paper explaining the transformers\n",
        "                  architecture. Be specific about graphs, such as bar plots.\"\"\"\n",
        "messages = [\n",
        "    (\n",
        "        \"user\",\n",
        "        [\n",
        "            {\"type\": \"text\", \"text\": prompt_template},\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "chain = prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
        "\n",
        "\n",
        "image_summaries = chain.batch(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "laF_8o1gzHT0",
      "metadata": {
        "id": "laF_8o1gzHT0"
      },
      "outputs": [],
      "source": [
        "image_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aHNDEd_2txQI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "aHNDEd_2txQI",
        "outputId": "fbd7c64e-f463-4203-e1ca-f79c7426aaf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image depicts two main concepts from the transformer architecture: **Scaled Dot-Product Attention** and **Multi-Head Attention**.\n",
            "\n",
            "### Scaled Dot-Product Attention (Left Side)\n",
            "1. **Structure**: \n",
            "   - The flow starts with three inputs represented as **Q** (Query), **K** (Key), and **V** (Value).\n",
            "   - The first operation is a **MatMul** (matrix multiplication) between Q and K, producing a score.\n",
            "   - This score is then passed to a **Scale** component, which adjusts the magnitude of the scores.\n",
            "   - An optional **Mask** is applied next to prevent certain positions from being attended to, often used in tasks like language modeling.\n",
            "   - The scores are then passed through a **SoftMax** layer to convert them into probabilities.\n",
            "   - Finally, another **MatMul** operation takes the output from SoftMax and multiplies it by V to produce the final attention output.\n",
            "\n",
            "### Multi-Head Attention (Right Side)\n",
            "1. **Structure**:\n",
            "   - This section builds upon the scaled dot-product attention.\n",
            "   - It begins with three linear transformations applied to V, K, and Q, indicated by three **Linear** blocks.\n",
            "   - These transformed vectors are then processed by the **Scaled Dot-Product Attention** block (highlighted in purple).\n",
            "   - The outputs from multiple attention heads are concatenated using the **Concat** operation.\n",
            "   - The final output from this multi-head attention structure is connected to another **Linear** layer.\n",
            "\n",
            "### Visual Elements:\n",
            "- **Color Coding**: Different components are color-coded for clarity, with purple for the main attention mechanism and other colors for supporting operations.\n",
            "- **Arrows**: Directional arrows indicate the flow of data through the various operations, demonstrating how inputs are transformed at each stage.\n",
            "- **Labels**: Clear labels for each component help in understanding the functionality of each part of the architecture.\n",
            "\n",
            "This diagram effectively illustrates how attention mechanisms are implemented in transformers, showcasing the sequential and parallel processing involved.\n"
          ]
        }
      ],
      "source": [
        "print(image_summaries[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b030d4-2ac5-41b6-9245-fc3ba5771d87",
      "metadata": {
        "id": "67b030d4-2ac5-41b6-9245-fc3ba5771d87"
      },
      "source": [
        "## Load data and summaries to vectorstore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb4d2379",
      "metadata": {
        "id": "bb4d2379"
      },
      "source": [
        "### Create the vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8d7a34-69e0-49a2-b9f7-1a4e7b26d78f",
      "metadata": {
        "id": "9d8d7a34-69e0-49a2-b9f7-1a4e7b26d78f",
        "outputId": "c91d7a77-d820-446f-a751-15f5d4668e8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lh/7g2mv_x16p79z2rd9jqxqx_w0000gn/T/ipykernel_92745/278287695.py:9: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n",
            "/var/folders/lh/7g2mv_x16p79z2rd9jqxqx_w0000gn/T/ipykernel_92745/278287695.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.schema.document import Document\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "# The retriever (empty to start)\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    id_key=id_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf26669",
      "metadata": {
        "id": "2bf26669"
      },
      "source": [
        "### Load the summaries and link the to the original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1792e683",
      "metadata": {
        "id": "1792e683"
      },
      "outputs": [],
      "source": [
        "# Add texts\n",
        "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
        "summary_texts = [\n",
        "    Document(page_content=summary, metadata={id_key: doc_ids[i]}) for i, summary in enumerate(text_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_texts)\n",
        "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
        "\n",
        "# Add tables\n",
        "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
        "summary_tables = [\n",
        "    Document(page_content=summary, metadata={id_key: table_ids[i]}) for i, summary in enumerate(table_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_tables)\n",
        "retriever.docstore.mset(list(zip(table_ids, tables)))\n",
        "\n",
        "# Add image summaries\n",
        "img_ids = [str(uuid.uuid4()) for _ in images]\n",
        "summary_img = [\n",
        "    Document(page_content=summary, metadata={id_key: img_ids[i]}) for i, summary in enumerate(image_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_img)\n",
        "retriever.docstore.mset(list(zip(img_ids, images)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b45fb81-46b1-426e-aa2c-01aed4eac700",
      "metadata": {
        "id": "4b45fb81-46b1-426e-aa2c-01aed4eac700"
      },
      "source": [
        "### Check retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bea75fe-85af-4955-a80c-6e0b44a8e215",
      "metadata": {
        "id": "1bea75fe-85af-4955-a80c-6e0b44a8e215"
      },
      "outputs": [],
      "source": [
        "# Retrieve\n",
        "docs = retriever.invoke(\n",
        "    \"who are the authors of the paper?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0290c78",
      "metadata": {
        "id": "a0290c78",
        "outputId": "d19cdecf-c9e6-4b40-f996-06041a7f0ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n",
            "\n",
            "[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.\n",
            "\n",
            "[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n",
            "\n",
            "[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n",
            "\n",
            "[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434–443. ACL, August 2013.\n",
            "\n",
            "12\n",
            "\n",
            "Attention Visualizations\n",
            "\n",
            "2 i i= RE 3 2 i 2 = = 2c 3 2 £ om % S GBANAAAA FS fe} oD DOD *H o Poe Q €oe2s oyzveyzuyeys 2SE @T_ EFESeSsEzESHR PL, SSSe TZSsSsggsg S=@LEGDEwB ECC oF aAeC RGN ESLSSSEESC -.VvVVVV VV HMO KEBOCSRSHLHOD QKXRDXE EO “A AAAAAA “= <2 £ 8 FogesouggsS ss P25 5273 Qvryxapvs\\3 es sa 5 Seeneteecorzgrs 2g ogs aaa oO 2 Sere =~ aA o ° 8 ueeeogoa0 o © £ 5 ane) vvvvv Vv £ eg € ° 2 Ss v Do <¢ 8 & |\n",
            "\n",
            "Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
            "\n",
            "13\n",
            "\n",
            "<ped> <ped> UOIUIdO == Aw ul Bulssiw ale « aM = yeum = S| sy ysnf pinoys = uoluldo Aw ul Bulssiw ae ysnf 38q Pinoys uojeojdde si! nq poped 38q JaAou Me] au <ped> <SOa> uojuido Aw ul Bulssiuw oe aM yeum S| SIU} ysnf 3q Pinoys uojeodde Ss}! ynq yoped 3q 4eAeuU meq auL <ped> <SOa> uo|uldo Aw ul Bulssiuw oe eM yeum S| Siu} ysnf 3q Pinoys uoyeoydde si! ynq yoped 3q aul\n",
            "\n",
            "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 and 6. Note that the attentions are very sharp for this word.\n",
            "\n",
            "14\n",
            "\n",
            "<ped> <ped> <SOH>\\ <SO3> uoluido = uoluido Aw Aw yeyum S| sim pi—f}— 4 -ysn{ | Pinoys «+ pinoys uoeoydde uojeodde SHI S$}! | ya | nga ynq poped pooped aq aq Janou™ J@AoU WIM TIM me) me) aul “OU\n",
            "\n",
            "<ped> <ped> so <0 Uo|UIdO uoluido Aw Aw ul ul Bulssiw Bulssiw ae ale aM am yeuM yeum S| S| sty} # sly -—A - el eq eq pinoys « pinoys uojeoidde ee Ss}! Ss}! nq ee popod a —_ ee eq eq JOAoU JOAoU IW IW rr auL auL\n",
            "\n",
            "Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
            "\n",
            "15\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser Training WSJ 23 F1 Vinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3 Petrov et al. (2006) [29] WSJ only, discriminative 90.4 Zhu et al. (2013) [40] WSJ only, discriminative 90.4 Dyer et al. (2016) [8] WSJ only, discriminative 91.7 Transformer (4 layers) WSJ only, discriminative 91.3 Zhu et al. (2013) [40] semi-supervised 91.3 Huang & Harper (2009) [14] semi-supervised 91.3 McClosky et al. (2006) [26] semi-supervised 92.1 Vinyals & Kaiser el al. (2014) [37] semi-supervised 92.1 Transformer (4 layers) semi-supervised 92.7 Luong et al. (2015) [23] multi-task 93.0 Dyer et al. (2016) [8] generative 93.3\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3\n",
            "\n",
            "2023\n",
            "\n",
            "2\n",
            "\n",
            "0\n",
            "\n",
            "2\n",
            "\n",
            "g u A 2 ] L C . s c [ 7 v 2 6 7 3 0 . 6 0\n",
            "\n",
            "7\n",
            "\n",
            "1\n",
            "\n",
            ":\n",
            "\n",
            "v\n",
            "\n",
            "arXiv\n",
            "\n",
            "i\n",
            "\n",
            "X\n",
            "\n",
            "r\n",
            "\n",
            "a\n",
            "\n",
            "Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works.\n",
            "\n",
            "Attention Is All You Need\n",
            "\n",
            "Ashish Vaswani∗\n",
            "\n",
            "Google Brain\n",
            "\n",
            "avaswani@google.com\n",
            "\n",
            "Noam Shazeer∗ Google Brain noam@google.com\n",
            "\n",
            "Niki Parmar∗ Google Research nikip@google.com\n",
            "\n",
            "Jakob Uszkoreit∗\n",
            "\n",
            "Google Research usz@google.com\n",
            "\n",
            "Llion Jones∗\n",
            "\n",
            "Google Research llion@google.com\n",
            "\n",
            "Aidan N. Gomez∗ † University of Toronto aidan@cs.toronto.edu\n",
            "\n",
            "Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com\n",
            "\n",
            "Illia Polosukhin∗ ‡\n",
            "\n",
            "illia.polosukhin@gmail.com\n",
            "\n",
            "Abstract\n",
            "\n",
            "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
            "\n",
            "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.\n",
            "\n",
            "†Work performed while at Google Brain.\n",
            "\n",
            "‡Work performed while at Google Research.\n",
            "\n",
            "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "N dmodel dff h dk dv Pdrop ϵls train steps PPL (dev) BLEU params (dev) ×106 base 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65 1 512 512 5.29 24.9 (A) 4 16 128 32 128 32 5.00 4.91 25.5 25.8 32 16 16 5.01 25.4 (B) 16 32 5.16 5.01 25.1 25.4 58 60 2 6.11 23.7 36 4 5.19 25.3 50 8 4.88 25.5 80 (C) 256 32 32 5.75 24.5 28 1024 128 128 4.66 26.0 168 1024 5.12 25.4 53 4096 4.75 26.2 90 0.0 5.77 24.6 (D) 0.2 0.0 4.95 4.67 25.5 25.3 0.2 5.47 25.7 (E) positional embedding instead of sinusoids 4.92 25.7\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "    print(str(doc) + \"\\n\\n\" + \"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69060724-e390-4dda-8250-5f86025c874a",
      "metadata": {
        "id": "69060724-e390-4dda-8250-5f86025c874a"
      },
      "source": [
        "## RAG pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "771a47fa-1267-4db8-a6ae-5fde48bbc069",
      "metadata": {
        "id": "771a47fa-1267-4db8-a6ae-5fde48bbc069"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from base64 import b64decode\n",
        "\n",
        "\n",
        "def parse_docs(docs):\n",
        "    \"\"\"Split base64-encoded images and texts\"\"\"\n",
        "    b64 = []\n",
        "    text = []\n",
        "    for doc in docs:\n",
        "        try:\n",
        "            b64decode(doc)\n",
        "            b64.append(doc)\n",
        "        except Exception as e:\n",
        "            text.append(doc)\n",
        "    return {\"images\": b64, \"texts\": text}\n",
        "\n",
        "\n",
        "def build_prompt(kwargs):\n",
        "\n",
        "    docs_by_type = kwargs[\"context\"]\n",
        "    user_question = kwargs[\"question\"]\n",
        "\n",
        "    context_text = \"\"\n",
        "    if len(docs_by_type[\"texts\"]) > 0:\n",
        "        for text_element in docs_by_type[\"texts\"]:\n",
        "            context_text += text_element.text\n",
        "\n",
        "    # construct prompt with context (including images)\n",
        "    prompt_template = f\"\"\"\n",
        "    Answer the question based only on the following context, which can include text, tables, and the below image.\n",
        "    Context: {context_text}\n",
        "    Question: {user_question}\n",
        "    \"\"\"\n",
        "\n",
        "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template}]\n",
        "\n",
        "    if len(docs_by_type[\"images\"]) > 0:\n",
        "        for image in docs_by_type[\"images\"]:\n",
        "            prompt_content.append(\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            HumanMessage(content=prompt_content),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        \"context\": retriever | RunnableLambda(parse_docs),\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | RunnableLambda(build_prompt)\n",
        "    | ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain_with_sources = {\n",
        "    \"context\": retriever | RunnableLambda(parse_docs),\n",
        "    \"question\": RunnablePassthrough(),\n",
        "} | RunnablePassthrough().assign(\n",
        "    response=(\n",
        "        RunnableLambda(build_prompt)\n",
        "        | ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "        | StrOutputParser()\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8414a8-65ee-4e11-8154-029b454f46af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "ea8414a8-65ee-4e11-8154-029b454f46af",
        "outputId": "2edf5f7e-9165-46ef-e710-cc945b78b230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The attention mechanism is a function that maps a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, with the weights determined by a compatibility function that measures how well the query aligns with each key.\n",
            "\n",
            "In mathematical terms, the attention function can be expressed as:\n",
            "\n",
            "\\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\]\n",
            "\n",
            "Here, \\(Q\\) represents the queries, \\(K\\) the keys, and \\(V\\) the values. The dot products of the queries and keys are scaled by the square root of the dimension of the keys (\\(d_k\\)) to prevent large values that could push the softmax function into regions with small gradients. This attention mechanism allows the model to focus on different parts of the input sequence when producing an output, enhancing its ability to handle dependencies and context within the data. \n",
            "\n",
            "Additionally, multi-head attention extends this concept by performing multiple attention operations in parallel, allowing the model to attend to information from different representation subspaces simultaneously.\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke(\n",
        "    \"What is the attention mechanism?\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4adfeba",
      "metadata": {
        "id": "e4adfeba",
        "outputId": "7c82360d-4c90-4cd1-9db4-7ba815277bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: Multi-head attention is a mechanism used in the Transformer model that allows the model to focus on different parts of the input sequence simultaneously. Instead of using a single attention function, multi-head attention uses multiple attention heads, each performing attention with different, learned linear projections of the queries, keys, and values. \n",
            "\n",
            "Here's a breakdown of how it works:\n",
            "\n",
            "1. **Linear Projections**: The queries (Q), keys (K), and values (V) are projected into different subspaces using learned linear transformations. Each head has its own set of projections.\n",
            "\n",
            "2. **Parallel Attention**: Each head computes attention independently, allowing the model to attend to various representation subspaces from different positions in the input sequence.\n",
            "\n",
            "3. **Concatenation**: The outputs from all heads are concatenated together.\n",
            "\n",
            "4. **Final Linear Projection**: The concatenated output is then projected again to produce the final output.\n",
            "\n",
            "This approach enables the model to capture a richer set of relationships in the data compared to a single attention head, which might average out important information. Multi-head attention is particularly beneficial for tasks that require understanding complex dependencies in sequences, such as natural language processing.\n",
            "\n",
            "\n",
            "Context:\n",
            "3.2.2 Multi-Head Attention\n",
            "\n",
            "Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
            "\n",
            "‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\n",
            "\n",
            "4\n",
            "\n",
            "output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\n",
            "\n",
            "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
            "\n",
            "MultiHead(Q, K, V ) = Concat(head1, ..., headh)W O where headi = Attention(QW Q i , KW K i , V W V i )\n",
            "\n",
            "Where the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk , W K i ∈ Rdmodel×dk , W V i ∈ Rdmodel×dv\n",
            "\n",
            "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\n",
            "\n",
            "3.2.3 Applications of Attention in our Model\n",
            "\n",
            "The Transformer uses multi-head attention in three different ways:\n",
            "\n",
            "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\n",
            "\n",
            "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
            "\n",
            "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.\n",
            "Page number:  4\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "big\n",
            "\n",
            "6\n",
            "\n",
            "1024\n",
            "\n",
            "4096\n",
            "\n",
            "16\n",
            "\n",
            "0.3\n",
            "\n",
            "300K 4.33\n",
            "\n",
            "26.4\n",
            "\n",
            "development set, newstest2013. We used beam search as described in the previous section, but no checkpoint averaging. We present these results in Table 3.\n",
            "\n",
            "In Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions, keeping the amount of computation constant, as described in Section 3.2.2. While single-head attention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\n",
            "\n",
            "In Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This suggests that determining compatibility is not easy and that a more sophisticated compatibility function than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected, bigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our sinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical results to the base model.\n",
            "\n",
            "6.3 English Constituency Parsing\n",
            "\n",
            "To evaluate if the Transformer can generalize to other tasks we performed experiments on English constituency parsing. This task presents specific challenges: the output is subject to strong structural constraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence models have not been able to attain state-of-the-art results in small-data regimes [37].\n",
            "\n",
            "We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the Penn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting, using the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences [37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens for the semi-supervised setting.\n",
            "\n",
            "We performed only a small number of experiments to select the dropout, both attention and residual (section 5.4), learning rates and beam size on the Section 22 development set, all other parameters remained unchanged from the English-to-German base translation model. During inference, we\n",
            "\n",
            "9\n",
            "\n",
            "213\n",
            "\n",
            "Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23 of WSJ)\n",
            "Page number:  9\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n",
            "\n",
            "[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems, 2015.\n",
            "\n",
            "[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n",
            "\n",
            "[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n",
            "\n",
            "[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434–443. ACL, August 2013.\n",
            "\n",
            "12\n",
            "\n",
            "Attention Visualizations\n",
            "\n",
            "2 i i= RE 3 2 i 2 = = 2c 3 2 £ om % S GBANAAAA FS fe} oD DOD *H o Poe Q €oe2s oyzveyzuyeys 2SE @T_ EFESeSsEzESHR PL, SSSe TZSsSsggsg S=@LEGDEwB ECC oF aAeC RGN ESLSSSEESC -.VvVVVV VV HMO KEBOCSRSHLHOD QKXRDXE EO “A AAAAAA “= <2 £ 8 FogesouggsS ss P25 5273 Qvryxapvs\\3 es sa 5 Seeneteecorzgrs 2g ogs aaa oO 2 Sere =~ aA o ° 8 ueeeogoa0 o © £ 5 ane) vvvvv Vv £ eg € ° 2 Ss v Do <¢ 8 & |\n",
            "\n",
            "Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
            "\n",
            "13\n",
            "\n",
            "<ped> <ped> UOIUIdO == Aw ul Bulssiw ale « aM = yeum = S| sy ysnf pinoys = uoluldo Aw ul Bulssiw ae ysnf 38q Pinoys uojeojdde si! nq poped 38q JaAou Me] au <ped> <SOa> uojuido Aw ul Bulssiuw oe aM yeum S| SIU} ysnf 3q Pinoys uojeodde Ss}! ynq yoped 3q 4eAeuU meq auL <ped> <SOa> uo|uldo Aw ul Bulssiuw oe eM yeum S| Siu} ysnf 3q Pinoys uoyeoydde si! ynq yoped 3q aul\n",
            "\n",
            "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 and 6. Note that the attentions are very sharp for this word.\n",
            "\n",
            "14\n",
            "\n",
            "<ped> <ped> <SOH>\\ <SO3> uoluido = uoluido Aw Aw yeyum S| sim pi—f}— 4 -ysn{ | Pinoys «+ pinoys uoeoydde uojeodde SHI S$}! | ya | nga ynq poped pooped aq aq Janou™ J@AoU WIM TIM me) me) aul “OU\n",
            "\n",
            "<ped> <ped> so <0 Uo|UIdO uoluido Aw Aw ul ul Bulssiw Bulssiw ae ale aM am yeuM yeum S| S| sty} # sly -—A - el eq eq pinoys « pinoys uojeoidde ee Ss}! Ss}! nq ee popod a —_ ee eq eq JOAoU JOAoU IW IW rr auL auL\n",
            "\n",
            "Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
            "\n",
            "15\n",
            "Page number:  12\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = chain_with_sources.invoke(\n",
        "    \"What is multihead?\"\n",
        ")\n",
        "\n",
        "print(\"Response:\", response['response'])\n",
        "\n",
        "print(\"\\n\\nContext:\")\n",
        "for text in response['context']['texts']:\n",
        "    print(text.text)\n",
        "    print(\"Page number: \", text.metadata.page_number)\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "for image in response['context']['images']:\n",
        "    display_base64_image(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90cd3714",
      "metadata": {
        "id": "90cd3714"
      },
      "source": [
        "## References\n",
        "\n",
        "- [LangChain Inspiration](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb?ref=blog.langchain.dev)\n",
        "- [Multivector Storage](https://python.langchain.com/docs/how_to/multi_vector/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "74b56bde-1ba0-4525-a11d-cab02c5659e4",
        "8b55862c",
        "b1feadda-8171-4aed-9a60-320a88dc9ee1",
        "bb4d2379",
        "2bf26669",
        "4b45fb81-46b1-426e-aa2c-01aed4eac700",
        "69060724-e390-4dda-8250-5f86025c874a"
      ]
    },
    "kernelspec": {
      "display_name": "mm-rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}